"""
Modu≈Ç do obs≈Çugi pyta≈Ñ otwartych z ocenƒÖ AI w systemie BVA
"""

import streamlit as st
from typing import Dict, List, Tuple
import json
import re

try:
    from openai import OpenAI
    openai_available = True
except ImportError:
    openai_available = False

class AIQuestionEvaluator:
    """Klasa do oceny odpowiedzi na pytania otwarte przy u≈ºyciu AI"""
    
    def __init__(self):
        # Sprawd≈∫ czy klucz API jest dostƒôpny
        self.api_key = st.secrets.get("OPENAI_API_KEY") if hasattr(st, 'secrets') else None
        if not self.api_key or not openai_available:
            st.warning("üîë Klucz API OpenAI nie jest skonfigurowany lub biblioteka OpenAI nie jest zainstalowana. Pytania otwarte bƒôdƒÖ dzia≈Çaƒá w trybie demo.")
            self.demo_mode = True
        else:
            self.demo_mode = False
            self.client = OpenAI(api_key=self.api_key)
    
    def evaluate_answer(self, question: str, user_answer: str, correct_answer: str, 
                       context: str = "", max_score: int = 10) -> Dict:
        """
        Ocenia odpowied≈∫ u≈ºytkownika na pytanie otwarte
        
        Args:
            question: Tre≈õƒá pytania
            user_answer: Odpowied≈∫ u≈ºytkownika
            correct_answer: Wzorcowa odpowied≈∫ lub kluczowe punkty
            context: Kontekst lekcji/tematu
            max_score: Maksymalna liczba punkt√≥w
            
        Returns:
            Dict z ocenƒÖ, feedbackiem i szczeg√≥≈Çami
        """
        
        if self.demo_mode:
            return self._demo_evaluation(user_answer, max_score)
        
        try:
            prompt = self._create_evaluation_prompt(question, user_answer, correct_answer, context, max_score)
            
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "Jeste≈õ ekspertem w dziedzinie neuroprzyw√≥dztwa i edukatorem. Twoim zadaniem jest sprawiedliwa i konstruktywna ocena odpowiedzi uczni√≥w."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=500,
                temperature=0.3
            )
            
            result = self._parse_ai_response(response.choices[0].message.content, max_score)
            return result
            
        except Exception as e:
            st.error(f"B≈ÇƒÖd podczas oceny odpowiedzi: {str(e)}")
            return self._fallback_evaluation(user_answer, max_score)
    
    def _create_evaluation_prompt(self, question: str, user_answer: str, 
                                correct_answer: str, context: str, max_score: int) -> str:
        """Tworzy prompt dla AI do oceny odpowiedzi"""
        
        return f"""
Oce≈Ñ nastƒôpujƒÖcƒÖ odpowied≈∫ ucznia na pytanie z zakresu neuroprzyw√≥dztwa:

KONTEKST LEKCJI: {context}

PYTANIE: {question}

ODPOWIED≈π UCZNIA: {user_answer}

WZORCOWA ODPOWIED≈π/KLUCZOWE PUNKTY: {correct_answer}

Oce≈Ñ odpowied≈∫ w skali 0-{max_score} punkt√≥w uwzglƒôdniajƒÖc:
1. Poprawno≈õƒá merytorycznƒÖ (50%)
2. Kompletno≈õƒá odpowiedzi (30%) 
3. Zrozumienie koncept√≥w (20%)

Podaj ocenƒô w formacie JSON:
{{
    "score": [liczba 0-{max_score}],
    "feedback": "[konstruktywny feedback dla ucznia]",
    "strong_points": "[co ucze≈Ñ zrobi≈Ç dobrze]",
    "areas_for_improvement": "[co mo≈ºna poprawiƒá]",
    "suggestions": "[konkretne sugestie do dalszej nauki]"
}}

Uwagi:
- BƒÖd≈∫ sprawiedliwy ale wymagajƒÖcy
- Doceniaj czƒô≈õciowo poprawne odpowiedzi
- Daj konstruktywny feedback
- U≈ºywaj jƒôzyka polskiego
- Je≈õli odpowied≈∫ jest bardzo kr√≥tka lub niejasna, wska≈º to delikatnie
"""
    
    def _parse_ai_response(self, response: str, max_score: int) -> Dict:
        """Parsuje odpowied≈∫ AI i zwraca ustrukturyzowany wynik"""
        
        try:
            # Spr√≥buj sparsowaƒá JSON
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                result = json.loads(json_match.group())
                
                # Walidacja i normalizacja
                score = min(max(int(result.get('score', 0)), 0), max_score)
                
                return {
                    'score': score,
                    'max_score': max_score,
                    'percentage': (score / max_score) * 100,
                    'feedback': result.get('feedback', 'Brak szczeg√≥≈Çowego feedbacku'),
                    'strong_points': result.get('strong_points', ''),
                    'areas_for_improvement': result.get('areas_for_improvement', ''),
                    'suggestions': result.get('suggestions', ''),
                    'passed': score >= (max_score * 0.6)  # 60% to zaliczenie
                }
        except:
            pass
        
        # Fallback parsing je≈õli JSON nie dzia≈Ça
        return self._fallback_evaluation(response, max_score)
    
    def _demo_evaluation(self, user_answer: str, max_score: int) -> Dict:
        """Tryb demo - prosta ocena bez AI"""
        
        # Prosta heurystyka na podstawie d≈Çugo≈õci odpowiedzi
        answer_length = len(user_answer.strip())
        
        if answer_length < 10:
            score = 2
            feedback = "Odpowied≈∫ jest bardzo kr√≥tka. Spr√≥buj rozwinƒÖƒá swojƒÖ my≈õl i podaƒá wiƒôcej szczeg√≥≈Ç√≥w."
        elif answer_length < 50:
            score = 4
            feedback = "Dobry poczƒÖtek! Twoja odpowied≈∫ zawiera podstawowe informacje, ale mo≈ºna jƒÖ rozszerzyƒá o wiƒôcej szczeg√≥≈Ç√≥w."
        elif answer_length < 150:
            score = 7
            feedback = "Bardzo dobra odpowied≈∫! Wykazujesz zrozumienie tematu. Mo≈ºna by jeszcze dodaƒá przyk≈Çady praktyczne."
        else:
            score = 9
            feedback = "Doskona≈Ça, szczeg√≥≈Çowa odpowied≈∫! Wykazujesz g≈Çƒôbokie zrozumienie zagadnienia."
        
        return {
            'score': score,
            'max_score': max_score,
            'percentage': (score / max_score) * 100,
            'feedback': feedback + " (Tryb demo - pe≈Çna ocena AI wymaga konfiguracji API)",
            'strong_points': "Dobra struktura odpowiedzi",
            'areas_for_improvement': "Spr√≥buj dodaƒá wiƒôcej przyk≈Çad√≥w praktycznych",
            'suggestions': "Poszukaj dodatkowych ≈∫r√≥de≈Ç na temat neuroprzyw√≥dztwa",
            'passed': score >= (max_score * 0.6)
        }
    
    def _fallback_evaluation(self, text: str, max_score: int) -> Dict:
        """Fallback w przypadku b≈Çƒôdu AI"""
        
        score = max_score // 2  # Po≈Çowa punkt√≥w jako fallback
        
        return {
            'score': score,
            'max_score': max_score,
            'percentage': 50.0,
            'feedback': "Dziƒôkujemy za odpowied≈∫. Ocena automatyczna nie jest obecnie dostƒôpna.",
            'strong_points': "PodjƒÖ≈Çe≈õ pr√≥bƒô odpowiedzi",
            'areas_for_improvement': "Sprawd≈∫ materia≈Çy lekcyjne",
            'suggestions': "Skonsultuj siƒô z instruktorem",
            'passed': True  # W trybie fallback zaliczamy
        }


def display_open_question(question_data: Dict, question_id: str) -> Tuple[bool, Dict]:
    """
    Wy≈õwietla pytanie otwarte z ocenƒÖ AI
    
    Args:
        question_data: Dane pytania (question, correct_answer, context, itp.)
        question_id: Unikalny identyfikator pytania
        
    Returns:
        Tuple (czy odpowiedziano, wynik oceny)
    """
    
    st.markdown(f"""
    <div class="open-question-container">
        <h4>üí≠ {question_data.get('question', 'Pytanie')}</h4>
    </div>
    """, unsafe_allow_html=True)
    
    # Sprawd≈∫ czy pytanie ju≈º zosta≈Ço odpowiedziane
    result_key = f"{question_id}_result"
    answer_key = f"{question_id}_answer"
    
    if result_key in st.session_state:
        # Wy≈õwietl poprzedni wynik
        result = st.session_state[result_key]
        prev_answer = st.session_state.get(answer_key, "")
        
        st.markdown('<div class="question-completed">', unsafe_allow_html=True)
        st.success(f"‚úÖ Pytanie zosta≈Ço ju≈º odpowiedziane! Otrzyma≈Çe≈õ {result['score']}/{result['max_score']} punkt√≥w ({result['percentage']:.1f}%)")
        
        with st.expander("üîç Zobacz swojƒÖ odpowied≈∫ i ocenƒô"):
            st.markdown("**Twoja odpowied≈∫:**")
            st.info(prev_answer)
            
            st.markdown("**Feedback:**")
            st.markdown(result['feedback'])
            
            if result['strong_points']:
                st.markdown("**‚úÖ Mocne strony:**")
                st.markdown(result['strong_points'])
            
            if result['areas_for_improvement']:
                st.markdown("**üéØ Obszary do poprawy:**")
                st.markdown(result['areas_for_improvement'])
            
            if result['suggestions']:
                st.markdown("**üí° Sugestie:**")
                st.markdown(result['suggestions'])
        
        # Przycisk ponownej pr√≥by
        if st.button("üîÑ Spr√≥buj ponownie", key=f"{question_id}_retry"):
            del st.session_state[result_key]
            if answer_key in st.session_state:
                del st.session_state[answer_key]
            st.rerun()
        
        st.markdown('</div>', unsafe_allow_html=True)
        return True, result
    
    # Wy≈õwietl pole do wprowadzenia odpowiedzi
    if question_data.get('context'):
        st.markdown(f"**Kontekst:** {question_data['context']}")
    
    if question_data.get('hints'):
        with st.expander("üí° Wskaz√≥wki"):
            for hint in question_data['hints']:
                st.markdown(f"‚Ä¢ {hint}")
    
    user_answer = st.text_area(
        "Twoja odpowied≈∫:",
        height=150,
        placeholder="Napisz swojƒÖ odpowied≈∫ tutaj...",
        key=f"{question_id}_input",
        help="Postaraj siƒô odpowiedzieƒá szczeg√≥≈Çowo i podaƒá przyk≈Çady je≈õli to mo≈ºliwe."
    )
    
    # Przycisk wys≈Çania odpowiedzi
    if st.button("üì§ Wy≈õlij odpowied≈∫", key=f"{question_id}_submit", disabled=not user_answer.strip()):
        if user_answer.strip():
            # Oce≈Ñ odpowied≈∫
            evaluator = AIQuestionEvaluator()
            
            with st.spinner("ü§ñ AI analizuje TwojƒÖ odpowied≈∫..."):
                result = evaluator.evaluate_answer(
                    question=question_data.get('question', ''),
                    user_answer=user_answer,
                    correct_answer=question_data.get('correct_answer', ''),
                    context=question_data.get('context', ''),
                    max_score=question_data.get('max_score', 10)
                )
            
            # Zapisz wynik
            st.session_state[result_key] = result
            st.session_state[answer_key] = user_answer
            
            st.rerun()
        else:
            st.warning("Proszƒô napisaƒá odpowied≈∫ przed wys≈Çaniem.")
    
    return False, {}


# Style CSS dla pyta≈Ñ otwartych
def load_open_question_styles():
    """≈Åaduje style CSS dla pyta≈Ñ otwartych"""
    
    st.markdown("""
    <style>
    .open-question-container {
        background: linear-gradient(135deg, #f0f8ff 0%, #e6f3ff 100%);
        padding: 20px;
        border-radius: 15px;
        margin: 20px 0;
        border-left: 5px solid #4A90E2;
        box-shadow: 0 4px 15px rgba(74, 144, 226, 0.1);
    }
    
    .open-question-container h4 {
        color: #2c5aa0;
        margin: 0;
        font-size: 1.3em;
    }
    
    .question-completed {
        background: linear-gradient(135deg, #f0fff0 0%, #e6ffe6 100%);
        padding: 20px;
        border-radius: 15px;
        margin: 20px 0;
        border-left: 5px solid #4CAF50;
        box-shadow: 0 4px 15px rgba(76, 175, 80, 0.1);
    }
    
    .stTextArea textarea {
        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        border-radius: 10px;
        border: 2px solid #e0e0e0;
        padding: 15px;
    }
    
    .stTextArea textarea:focus {
        border-color: #4A90E2;
        box-shadow: 0 0 10px rgba(74, 144, 226, 0.2);
    }
    </style>
    """, unsafe_allow_html=True)
