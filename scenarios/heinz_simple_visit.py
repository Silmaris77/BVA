"""
üéØ Heinz - Prosty Scenariusz Wizyty Handlowej

Najprostszy mo≈ºliwy scenariusz:
- AI gra klienta (w≈Ça≈õciciela bistro)
- Gracz prowadzi rozmowƒô handlowƒÖ
- Ocena i feedback tylko na ko≈Ñcu
"""

from typing import Dict, List, Tuple, Optional
from datetime import datetime
import google.generativeai as genai
import streamlit as st
import os


class HeinzSimpleVisitScenario:
    """Prosty scenariusz wizyty handlowej Heinz"""
    
    def __init__(self, api_key: Optional[str] = None):
        """
        Args:
            api_key: Klucz API do Gemini (opcjonalny, pobierze z secrets)
        """
        if not api_key:
            api_key = self._get_api_key()
        
        if api_key:
            genai.configure(api_key=api_key)
            self.model = genai.GenerativeModel("gemini-2.0-flash-exp")
        else:
            self.model = None
            
    def _get_api_key(self) -> Optional[str]:
        """Pobiera klucz API z secrets lub environment"""
        # Try Streamlit secrets first
        try:
            if hasattr(st, 'secrets') and 'API_KEYS' in st.secrets:
                if 'GEMINI_API_KEY' in st.secrets['API_KEYS']:
                    return st.secrets['API_KEYS']['GEMINI_API_KEY']
        except:
            pass
        
        # Try config file
        try:
            current_dir = os.path.dirname(os.path.abspath(__file__))
            base_dir = os.path.dirname(current_dir)
            api_key_file = os.path.join(base_dir, "config", "gemini_api_key.txt")
            
            if os.path.exists(api_key_file):
                with open(api_key_file, 'r') as f:
                    key = f.read().strip()
                    if key:
                        return key
        except:
            pass
        
        # Try environment variable
        return os.getenv('GEMINI_API_KEY')
        
    def get_client_profile(self) -> Dict:
        """Zwraca profil klienta dla tego scenariusza"""
        return {
            "id": "michal_bistro",
            "name": "Bistro U Micha≈Ça",
            "owner": "Micha≈Ç Kowalski",
            "avatar": "üë®‚Äçüç≥",
            "type": "bistro",
            "segment": "HoReCa ma≈Çe",
            "location": "Warszawa, Mokot√≥w",
            
            # Profil psychologiczny
            "personality": {
                "type": "pragmatyczny_oszczƒôdny",
                "description": "Liczy ka≈ºdƒÖ z≈Çot√≥wkƒô, ale ceni jako≈õƒá. Nie lubi agresywnej sprzeda≈ºy.",
                "openness": 6,  # 1-10, jak otwarty na nowe produkty
                "trust_level": 4,  # 1-10, poczƒÖtkowy poziom zaufania
            },
            
            # Obecna sytuacja
            "current_situation": {
                "ketchup_supplier": "Pudliszki",
                "monthly_ketchup_usage_kg": 8,  # ~2 butelki 5kg/miesiƒÖc
                "current_price_per_kg": 8.50,
                "satisfaction_with_current": 7,  # 1-10
                "main_pain_point": "Klienci czasem pytajƒÖ o Heinz"
            },
            
            # Co klient chce us≈Çyszeƒá
            "decision_factors": [
                "Konkretna korzy≈õƒá finansowa (mar≈ºa)",
                "Dow√≥d ≈ºe klienci preferujƒÖ Heinz",
                "Gwarancja jako≈õci",
                "≈Åatwa dostƒôpno≈õƒá/dostawa"
            ],
            
            # Informacje kt√≥re klient mo≈ºe ujawniƒá
            "hidden_info": {
                "budget_flexibility": "Ma ~500 PLN bud≈ºetu na testy nowych produkt√≥w",
                "vip_customers": "Ma kilku sta≈Çych klient√≥w-freak√≥w Heinz",
                "competition": "SƒÖsiednie bistro ma Heinz i siƒô chwali",
                "real_pain": "Pudliszki czasem ko≈ÑczƒÖ siƒô u dostawcy"
            }
        }
    
    def start_conversation(self, client: Dict) -> str:
        """
        Rozpoczyna rozmowƒô - AI przedstawia siƒô jako klient
        
        Returns:
            PoczƒÖtkowa wypowied≈∫ klienta
        """
        if not self.model:
            return "Dzie≈Ñ dobry! S≈Çucham?"
            
        prompt = f"""Wciel siƒô w {client['owner']}, w≈Ça≈õciciela {client['name']}.

TW√ìJ CHARAKTER:
{client['personality']['description']}

SYTUACJA:
- U≈ºywasz teraz: {client['current_situation']['ketchup_supplier']}
- Zu≈ºycie: ~{client['current_situation']['monthly_ketchup_usage_kg']} kg/miesiƒÖc
- Jeste≈õ zadowolony na {client['current_situation']['satisfaction_with_current']}/10

Do Twojego bistro wchodzi handlowiec Heinz.

WA≈ªNE - ZASADY GRY:
1. Odpowiadaj TYLKO jako w≈Ça≈õciciel bistro
2. BƒÖd≈∫ uprzejmy ale ostro≈ºny
3. Nie ujawniaj od razu wszystkich informacji
4. Zadawaj pytania kontrowne
5. NIE OCENIAJ handlowca - po prostu prowad≈∫ rozmowƒô

Przywitaj handlowca kr√≥tko (2-3 zdania). BƒÖd≈∫ uprzejmy ale nie entuzjastyczny."""

        try:
            response = self.model.generate_content(
                prompt,
                generation_config=genai.types.GenerationConfig(
                    temperature=0.9,
                    top_p=0.95,
                    max_output_tokens=300,
                )
            )
            return response.text.strip()
        except Exception as e:
            print(f"Error in start_conversation: {e}")
            return "Dzie≈Ñ dobry! S≈Çucham?"
    
    def continue_conversation(
        self, 
        client: Dict, 
        conversation_history: List[Dict],
        player_message: str
    ) -> str:
        """
        Kontynuuj rozmowƒô - AI odpowiada jako klient
        
        Args:
            client: Profil klienta
            conversation_history: Historia wiadomo≈õci [{role, content}, ...]
            player_message: Ostatnia wiadomo≈õƒá gracza
            
        Returns:
            Odpowied≈∫ klienta
        """
        if not self.model:
            return "Rozumiem. A co jeszcze chcia≈Çby Pan powiedzieƒá?"
            
        # Zbuduj historiƒô dla AI
        conversation_text = "\n\n".join([
            f"{'Handlowiec' if msg['role'] == 'user' else client['owner']}: {msg['content']}"
            for msg in conversation_history[:-1]  # Exclude last message (it's player_message)
        ])
        
        prompt = f"""Wciel siƒô w {client['owner']}, w≈Ça≈õciciela {client['name']}.

TW√ìJ CHARAKTER:
{client['personality']['description']}

AKTUALNA SYTUACJA:
- Obecny dostawca: {client['current_situation']['ketchup_supplier']}
- Satysfakcja: {client['current_situation']['satisfaction_with_current']}/10
- Problem: {client['current_situation']['main_pain_point']}

CO CIEBIE PRZEKONUJE:
{chr(10).join('- ' + factor for factor in client['decision_factors'])}

HISTORIA ROZMOWY DO TEJ PORY:
{conversation_text}

HANDLOWIEC W≈ÅA≈öNIE POWIEDZIA≈Å:
"{player_message}"

WA≈ªNE ZASADY:
1. Odpowiadaj TYLKO jako w≈Ça≈õciciel - NIE OCENIAJ handlowca
2. Reaguj naturalnie na jego argumenty
3. Zadawaj pytania je≈õli co≈õ Ciƒô zainteresuje
4. Ujawniaj informacje stopniowo (nie wszystko od razu)
5. BƒÖd≈∫ realistyczny - prawdziwy klient nie zgadza siƒô od razu
6. Je≈õli handlowiec trafi w Twoje potrzeby - poka≈º zainteresowanie
7. Je≈õli nie - wyra≈∫ wƒÖtpliwo≈õci
8. M√≥w naturalnie, potocznie - jeste≈õ w≈Ça≈õcicielem bistro, nie profesorem

Odpowiedz kr√≥tko (2-4 zdania) jako w≈Ça≈õciciel bistro:"""

        try:
            response = self.model.generate_content(
                prompt,
                generation_config=genai.types.GenerationConfig(
                    temperature=0.9,
                    top_p=0.95,
                    max_output_tokens=400,
                )
            )
            return response.text.strip()
        except Exception as e:
            print(f"Error in continue_conversation: {e}")
            return "Rozumiem. A co jeszcze chcia≈Çby Pan powiedzieƒá?"
    
    def evaluate_conversation(
        self,
        client: Dict,
        conversation_history: List[Dict]
    ) -> Tuple[int, str, Dict]:
        """
        Oce≈Ñ ca≈ÇƒÖ rozmowƒô - DOPIERO NA KO≈ÉCU
        
        Returns:
            (score, feedback, analysis)
            - score: 0-100
            - feedback: Tekstowy feedback w formacie FUKO
            - analysis: S≈Çownik z detalami
        """
        if not self.model:
            return (
                50,
                "System oceny niedostƒôpny (brak API key).",
                {"error": "no_api_key"}
            )
            
        conversation_text = "\n\n".join([
            f"{'Handlowiec' if msg['role'] == 'user' else 'Klient'}: {msg['content']}"
            for msg in conversation_history
        ])
        
        prompt = f"""Jeste≈õ ekspertem sprzeda≈ºy B2B w bran≈ºy food service.

Oce≈Ñ poni≈ºszƒÖ rozmowƒô handlowƒÖ pod kƒÖtem skuteczno≈õci sprzeda≈ºy Heinz Ketchup.

PROFIL KLIENTA:
- Typ: {client['personality']['type']}
- Opis: {client['personality']['description']}
- Co go przekonuje: {', '.join(client['decision_factors'])}
- Obecny problem: {client['current_situation']['main_pain_point']}

ROZMOWA:
{conversation_text}

OCE≈É (0-100 punkt√≥w) wed≈Çug kryteri√≥w:
1. **Budowanie Relacji** (0-25): Czy handlowiec budowa≈Ç rapport i zaufanie?
2. **Odkrywanie Potrzeb** (0-25): Czy zadawa≈Ç pytania odkrywajƒÖce potrzeby?
3. **Dopasowanie Argument√≥w** (0-25): Czy argumenty trafia≈Çy w potrzeby klienta?
4. **Zamkniƒôcie** (0-25): Czy pr√≥bowa≈Ç doprowadziƒá do decyzji/kolejnego kroku?

WA≈ªNE - Zwr√≥ƒá odpowied≈∫ w CZYSTYM formacie JSON (bez markdown, bez ```json):
{{
    "score": <liczba 0-100>,
    "breakdown": {{
        "building_rapport": <0-25>,
        "discovery": <0-25>,
        "argumentation": <0-25>,
        "closing": <0-25>
    }},
    "strengths": ["mocna strona 1", "mocna strona 2"],
    "weaknesses": ["s≈Çabo≈õƒá 1", "s≈Çabo≈õƒá 2"],
    "fuko_feedback": "Feedback w formacie FUKO (Fakty-Uczucia-Konsekwencje-Oczekiwania). U≈ºywaj drugiej osoby (Ty).",
    "order_likely": true/false,
    "order_size_kg": <szacowana wielko≈õƒá zam√≥wienia w kg, 0 je≈õli brak>,
    "next_steps": "Co handlowiec powinien zrobiƒá dalej"
}}"""

        try:
            response = self.model.generate_content(
                prompt,
                generation_config=genai.types.GenerationConfig(
                    temperature=0.3,
                    top_p=0.9,
                    max_output_tokens=1000,
                )
            )
            
            # Parse JSON response
            import json
            import re
            
            response_text = response.text.strip()
            
            # Remove markdown code blocks if present
            response_text = re.sub(r'```json\s*', '', response_text)
            response_text = re.sub(r'```\s*$', '', response_text)
            response_text = response_text.strip()
            
            result = json.loads(response_text)
            
            return (
                result['score'],
                result['fuko_feedback'],
                result
            )
        except Exception as e:
            print(f"Error in evaluate_conversation: {e}")
            # Fallback je≈õli JSON nie zadzia≈Ça≈Ç
            return (
                50,
                "Nie uda≈Ço siƒô przeanalizowaƒá rozmowy automatycznie. Spr√≥buj ponownie lub skontaktuj siƒô z administratorem.",
                {"error": str(e)}
            )
