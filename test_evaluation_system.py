"""
Test systemu oceny kontraktÃ³w Business Games
Testuje 3 tryby: Heurystyka, AI (mock), Mistrz Gry
"""

import sys
import os

# Dodaj Å›cieÅ¼kÄ™ projektu do PYTHONPATH
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from utils.business_game_evaluation import (
    evaluate_contract_solution,
    evaluate_heuristic,
    queue_for_game_master,
    get_pending_reviews_count,
    get_pending_contract_reviews,
    submit_game_master_review,
    set_active_evaluation_mode,
    get_active_evaluation_mode
)

# =============================================================================
# TEST 1: HEURYSTYKA
# =============================================================================

def test_heuristic_evaluation():
    """Test oceny heurystycznej"""
    print("=" * 70)
    print("TEST 1: OCENA HEURYSTYCZNA")
    print("=" * 70)
    
    # Mock kontrakt
    contract = {
        "id": "TEST-001",
        "tytul": "Test Conflict Resolution",
        "kategoria": "Konflikt",
        "poziom_trudnosci": 3,
        "opis": "RozwiÄ…Å¼ konflikt w zespole",
        "min_slow": 300,
        "nagroda_base": 500
    }
    
    # KrÃ³tkie rozwiÄ…zanie (poniÅ¼ej minimum)
    short_solution = " ".join(["sÅ‚owo"] * 100)  # 100 sÅ‚Ã³w
    rating, feedback, details = evaluate_heuristic(short_solution, contract)
    
    print(f"\nğŸ“ KrÃ³tkie rozwiÄ…zanie (100 sÅ‚Ã³w):")
    print(f"   Ocena: {rating}â­")
    print(f"   Feedback: {feedback}")
    print(f"   SzczegÃ³Å‚y: {details}")
    
    assert rating >= 1 and rating <= 5, "Ocena powinna byÄ‡ w zakresie 1-5"
    assert details['word_count'] == 100, "Liczba sÅ‚Ã³w niezgodna"
    
    # Åšrednie rozwiÄ…zanie (ok minimum)
    medium_solution = " ".join(["sÅ‚owo"] * 300)  # 300 sÅ‚Ã³w
    rating, feedback, details = evaluate_heuristic(medium_solution, contract)
    
    print(f"\nğŸ“ Åšrednie rozwiÄ…zanie (300 sÅ‚Ã³w):")
    print(f"   Ocena: {rating}â­")
    print(f"   Feedback: {feedback}")
    
    # DÅ‚ugie rozwiÄ…zanie (powyÅ¼ej minimum)
    long_solution = " ".join(["sÅ‚owo"] * 600)  # 600 sÅ‚Ã³w
    rating, feedback, details = evaluate_heuristic(long_solution, contract)
    
    print(f"\nğŸ“ DÅ‚ugie rozwiÄ…zanie (600 sÅ‚Ã³w):")
    print(f"   Ocena: {rating}â­")
    print(f"   Feedback: {feedback}")
    
    print("\nâœ… Test heurystyki zakoÅ„czony pomyÅ›lnie!\n")


# =============================================================================
# TEST 2: MISTRZ GRY (kolejka)
# =============================================================================

def test_game_master_queue():
    """Test kolejki Mistrza Gry"""
    print("=" * 70)
    print("TEST 2: KOLEJKA MISTRZA GRY")
    print("=" * 70)
    
    # Mock user_data
    user_data = {
        "username": "testuser",
        "name": "Test User",
        "degencoins": 1000
    }
    
    # Mock kontrakt
    contract = {
        "id": "TEST-GM-001",
        "tytul": "Test Coaching Session",
        "kategoria": "Coaching",
        "poziom_trudnosci": 4,
        "opis": "PrzeprowadÅº sesjÄ™ coachingowÄ…",
        "min_slow": 400,
        "nagroda_base": 800,
        "nagroda_4star": 1200,
        "nagroda_5star": 1600
    }
    
    solution = " ".join(["rozwiÄ…zanie"] * 450)  # 450 sÅ‚Ã³w
    
    print("\nğŸ“¤ Dodawanie do kolejki...")
    rating, feedback, details = queue_for_game_master(user_data, contract, solution)
    
    print(f"\n   Rating: {rating} (0 = pending)")
    print(f"   Feedback: {feedback[:100]}...")
    print(f"   Review ID: {details['review_id']}")
    
    assert rating == 0, "Rating powinien byÄ‡ 0 dla pending"
    assert details['status'] == 'pending', "Status powinien byÄ‡ pending"
    
    # SprawdÅº kolejkÄ™
    pending_count = get_pending_reviews_count()
    print(f"\nğŸ“‹ OczekujÄ…ce oceny: {pending_count}")
    
    assert pending_count > 0, "Powinna byÄ‡ co najmniej jedna oczekujÄ…ca ocena"
    
    # Pobierz listÄ™
    pending_reviews = get_pending_contract_reviews()
    print(f"\nğŸ“‹ Lista oczekujÄ…cych ({len(pending_reviews)}):")
    
    for review in pending_reviews[:3]:  # PokaÅ¼ max 3
        print(f"   - {review['username']}: {review['contract_title']} ({review['waiting_hours']}h)")
    
    # Symuluj ocenÄ™ przez Mistrza Gry
    if pending_reviews:
        review_to_evaluate = pending_reviews[0]
        print(f"\nğŸ‘¨â€ğŸ’¼ Mistrz Gry ocenia: {review_to_evaluate['id']}")
        
        success = submit_game_master_review(
            review_id=review_to_evaluate['id'],
            rating=5,
            feedback="DoskonaÅ‚a praca! Åšwietne zastosowanie technik CIQ.",
            admin_username="admin_test"
        )
        
        if success:
            print("   âœ… Ocena zatwierdzona!")
            
            # SprawdÅº czy zmniejszyÅ‚a siÄ™ kolejka
            new_pending_count = get_pending_reviews_count()
            print(f"   ğŸ“‹ OczekujÄ…ce oceny teraz: {new_pending_count}")
        else:
            print("   âš ï¸ Nie udaÅ‚o siÄ™ zatwierdziÄ‡ (moÅ¼liwe Å¼e uÅ¼ytkownik nie istnieje w bazie)")
    
    print("\nâœ… Test kolejki Mistrza Gry zakoÅ„czony!\n")


# =============================================================================
# TEST 3: ZMIANA TRYBU
# =============================================================================

def test_mode_switching():
    """Test zmiany trybÃ³w oceny"""
    print("=" * 70)
    print("TEST 3: ZMIANA TRYBÃ“W OCENY")
    print("=" * 70)
    
    # SprawdÅº aktualny tryb
    current_mode = get_active_evaluation_mode()
    print(f"\nğŸ“ Aktualny tryb: {current_mode}")
    
    # ZmieÅ„ na heurystykÄ™
    print("\nğŸ”„ Zmiana na heurystykÄ™...")
    success = set_active_evaluation_mode("heuristic")
    
    if success:
        new_mode = get_active_evaluation_mode()
        print(f"   âœ… Nowy tryb: {new_mode}")
        assert new_mode == "heuristic", "Tryb powinien byÄ‡ heuristic"
    
    # ZmieÅ„ na game_master
    print("\nğŸ”„ Zmiana na Mistrza Gry...")
    success = set_active_evaluation_mode("game_master")
    
    if success:
        new_mode = get_active_evaluation_mode()
        print(f"   âœ… Nowy tryb: {new_mode}")
        assert new_mode == "game_master", "Tryb powinien byÄ‡ game_master"
    
    # PrÃ³ba ustawienia nieprawidÅ‚owego trybu
    print("\nğŸ”„ PrÃ³ba ustawienia nieprawidÅ‚owego trybu...")
    success = set_active_evaluation_mode("invalid_mode")
    
    if not success:
        print("   âœ… Poprawnie odrzucono nieprawidÅ‚owy tryb")
    
    # PrzywrÃ³Ä‡ domyÅ›lny
    print("\nğŸ”„ Przywracanie domyÅ›lnego trybu (heuristic)...")
    set_active_evaluation_mode("heuristic")
    
    print("\nâœ… Test zmiany trybÃ³w zakoÅ„czony!\n")


# =============================================================================
# TEST 4: INTEGRACJA Z BUSINESS GAME
# =============================================================================

def test_integration():
    """Test integracji z business_game.py"""
    print("=" * 70)
    print("TEST 4: INTEGRACJA Z BUSINESS GAME")
    print("=" * 70)
    
    # Mock user_data z Business Games
    user_data = {
        "username": "integration_test",
        "degencoins": 5000,
        "business_game": {
            "firm": {
                "name": "Test Consulting",
                "level": 2,
                "reputation": 100
            },
            "contracts": {
                "active": [{
                    "id": "INTEGRATION-001",
                    "tytul": "Test Integration Contract",
                    "kategoria": "Leadership",
                    "poziom_trudnosci": 3,
                    "opis": "Test integracji",
                    "min_slow": 300,
                    "nagroda_base": 600,
                    "nagroda_3star": 600,
                    "nagroda_4star": 900,
                    "nagroda_5star": 1200
                }],
                "completed": []
            },
            "stats": {
                "contracts_completed": 0,
                "contracts_5star": 0,
                "contracts_4star": 0,
                "contracts_3star": 0,
                "contracts_2star": 0,
                "contracts_1star": 0,
                "total_revenue": 0,
                "category_stats": {}
            },
            "history": {
                "transactions": []
            }
        }
    }
    
    contract = user_data["business_game"]["contracts"]["active"][0]
    solution = " ".join(["test"] * 350)  # 350 sÅ‚Ã³w
    
    print(f"\nğŸ“ Kontrakt: {contract['tytul']}")
    print(f"   TrudnoÅ›Ä‡: {contract['poziom_trudnosci']}â­")
    print(f"   RozwiÄ…zanie: {len(solution.split())} sÅ‚Ã³w")
    
    # Ustaw tryb na heurystykÄ™
    set_active_evaluation_mode("heuristic")
    
    # OceÅ„ przez system
    rating, feedback, details = evaluate_contract_solution(
        user_data=user_data,
        contract=contract,
        solution=solution
    )
    
    print(f"\nâ­ Ocena: {rating}/5")
    print(f"ğŸ“„ Feedback: {feedback}")
    print(f"ğŸ”§ Metoda: {details['method']}")
    
    assert rating >= 1 and rating <= 5, "Ocena powinna byÄ‡ w zakresie 1-5"
    assert details['method'] == 'heuristic', "Metoda powinna byÄ‡ heuristic"
    
    print("\nâœ… Test integracji zakoÅ„czony!\n")


# =============================================================================
# URUCHOM WSZYSTKIE TESTY
# =============================================================================

if __name__ == "__main__":
    print("\n")
    print("ğŸ§ª " + "=" * 66 + " ğŸ§ª")
    print("   TEST SYSTEMU OCENY KONTRAKTÃ“W - BUSINESS GAMES")
    print("ğŸ§ª " + "=" * 66 + " ğŸ§ª")
    print("\n")
    
    try:
        # Test 1
        test_heuristic_evaluation()
        
        # Test 2
        test_game_master_queue()
        
        # Test 3
        test_mode_switching()
        
        # Test 4
        test_integration()
        
        # Podsumowanie
        print("=" * 70)
        print("ğŸ‰ WSZYSTKIE TESTY ZAKOÅƒCZONE POMYÅšLNIE! ğŸ‰")
        print("=" * 70)
        print("\nâœ… System oceny kontraktÃ³w dziaÅ‚a poprawnie")
        print("âœ… Wszystkie 3 tryby zaimplementowane:")
        print("   - âš¡ Heurystyka (automatyczna, szybka)")
        print("   - ğŸ¤– AI (OpenAI GPT - wymaga API key)")
        print("   - ğŸ‘¨â€ğŸ’¼ Mistrz Gry (rÄ™czna ocena przez Admina)")
        print("\nğŸ“‹ NastÄ™pne kroki:")
        print("   1. Przetestuj w aplikacji Streamlit")
        print("   2. Dodaj klucz API OpenAI dla trybu AI")
        print("   3. OceÅ„ kilka kontraktÃ³w jako Mistrz Gry")
        print("\n")
        
    except AssertionError as e:
        print(f"\nâŒ TEST NIEUDANY: {e}\n")
    except Exception as e:
        print(f"\nâŒ BÅÄ„D: {e}\n")
        import traceback
        traceback.print_exc()
